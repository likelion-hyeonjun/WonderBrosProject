{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2333eee00f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;31m#resume일 경우?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfineTuningModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'densenet121'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#is freeze, pretrained 넣어주기\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m#use deformable !!should modify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "'''Train CIFAR10 with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from deformable_filter import *\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from models import *\n",
    "from utils import fineTuningModel\n",
    "from train import train\n",
    "from test import Test\n",
    "\n",
    "# def str2bool(v):\n",
    "#     if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "#         return True\n",
    "#     elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "#         return False\n",
    "#     else:\n",
    "#         raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "# #오늘 모델돌릴수있는데까지 짜고 내일 state이거해야겠다\n",
    "# parser = argparse.ArgumentParser(description='GroceryDataset Training with VGG, ResNet and DenseNet')\n",
    "# parser.add_argument('--model', \n",
    "#                     default ='vgg19',\n",
    "#                     help='choose model for experiment \\n available params: densenet, resnet, vgg19')\n",
    "# parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
    "# parser.add_argument('--epoch', type=int, default=50, help='# of epoch')\n",
    "# parser.add_argument('--train_batch_size', type=int, default=1, help='# images in batch when training')\n",
    "# parser.add_argument('--test_batch_size', type=int, default=1, help='# images in batch when testing')\n",
    "# parser.add_argument('--opt', default='SGD', help='optimizer')\n",
    "# parser.add_argument('--freeze', type=str2bool ,default=\"true\", help='true: fine-tuning for only classifier layer, false: fine-tuning for whole layer (with pretrained)')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # 추가해야할 부분 fint turning 관련된 arg, data augmentation 관련 arg\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# # DataSet\n",
    "# print('==> Preparing data..')\n",
    "# preprocess_densenet = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "# ])\n",
    "\n",
    "# preprocess_vgg = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "# preprocess_resnet = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "# ])\n",
    "\n",
    "# if 'vgg' in args.model :\n",
    "#     preprocess = preprocess_vgg\n",
    "# elif 'resnet' in args.model :\n",
    "#     preprocess = preprocess_resnet\n",
    "# elif 'densenet' in args.model :\n",
    "#     preprocess = preprocess_densenet\n",
    "\n",
    "# trainDataPath = trainDataPath = os.getcwd()+\"/GroceryStoreDataset-master/dataset/train/Packages\"\n",
    "# train_dataset = ImageFolder(root=trainDataPath, transform = preprocess)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "#                                             batch_size=args.train_batch_size,\n",
    "#                                             shuffle = True)\n",
    "# testDataPath = os.getcwd()+\"/GroceryStoreDataset-master/dataset/test/Packages\"\n",
    "# test_dataset = ImageFolder(root=testDataPath, transform = preprocess) #이거 test시에해야하나?\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "#                                           batch_size = args.test_batch_size,\n",
    "#                                           shuffle = False)\n",
    "# validDataPath = os.getcwd()+\"/GroceryStoreDataset-master/dataset/val/Packages\"\n",
    "# valid_dataset = ImageFolder(root=validDataPath, transform = preprocess)\n",
    "# valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "#                                           batch_size = args.test_batch_size,\n",
    "#                                           shuffle = False)\n",
    "# # Model\n",
    "# print('==> Building model..')\n",
    "\n",
    "classes = ('Alpro-Blueberry-Soyghurt','Alpro-Fresh-Soy-Milk',\n",
    "            'Alpro-Shelf-Soy-Milk', 'Alpro-Vanilla-Soyghurt',\n",
    "            'Arla-Ecological-Medium-Fat-Milk', 'Arla-Ecological-Sour-Cream',\n",
    "            'Arla-Lactose-Medium-Fat-Milk', 'Arla-Medium-Fat-Milk',\n",
    "            'Arla-Mild-Vanilla-Yoghurt', 'Arla-Natural-Mild-Low-Fat-Yoghurt',\n",
    "            'Arla-Natural-Yoghurt','Arla-Sour-Cream',\n",
    "            'Arla-Sour-Milk','Arla-Standard-Milk',\n",
    "            'Bravo-Apple-Juice', 'Bravo-Orange-Juice',\n",
    "            'Garant-Ecological-Medium-Fat-Milk', 'Garant-Ecological-Standard-Milk',\n",
    "            'God-Morgon-Apple-Juice', 'God-Morgon-Orange-Juice',\n",
    "            'God-Morgon-Orange-Red-Grapefruit-Juice', 'God-Morgon-Red-Grapefruit-Juice',\n",
    "            'Oatly-Natural-Oatghurt', 'Oatly-Oat-Milk',\n",
    "            'Tropicana-Apple-Juice', 'Tropicana-Golden-Grapefruit',\n",
    "            'Tropicana-Juice-Smooth', 'Tropicana-Mandarin-Morning',\n",
    "            'Valio-Vanilla-Yoghurt', 'Yoggi-Strawberry-Yoghurt',\n",
    "            'Yoggi-Vanilla-Yoghurt')\n",
    "\n",
    "\n",
    "#resume일 경우?\n",
    "model = fineTuningModel('densenet121', len(classes), True, True) #is freeze, pretrained 넣어주기\n",
    "\n",
    "#use deformable !!should modify\n",
    "print(model.features[-2][2])\n",
    "if args.model == 'densenet121':\n",
    "    #denseblock 4, denselayer16, last conv filter\n",
    "    model.features[-2][-1][-1] = deformable_filter(128, 18)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr,\n",
    "                      momentum=0.9, weight_decay=5e-4)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "#그냥 트레인으로만들자..  early stopping 넣어서\n",
    "#해야할거 validation set만들기 그리고 train에 early stopping 하기. \n",
    "# train때 load state dict하기 \n",
    "\n",
    "\n",
    "trained_model = train(model = model, \n",
    "                    train_loader = train_loader, \n",
    "                    valid_loader = valid_loader,\n",
    "                    criterion = criterion, \n",
    "                    optimizer = optimizer, \n",
    "                    scheduler = exp_lr_scheduler, \n",
    "                    device = device, \n",
    "                    num_train_data =len(train_dataset), \n",
    "                    num_valid_data = len(valid_dataset), \n",
    "                    num_epochs = args.epoch)\n",
    "test_model = Test(trained_model, test_loader, len(test_dataset))\n",
    "test_model.OverallAccuracy()\n",
    "test_model.ClassAccuracy(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
